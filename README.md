 ğŸ¤– Robotic Arm Pick and Place Simulation

A complete simulation of a robotic arm trained using Reinforcement Learning (PPO) in PyBullet, capable of performing autonomous pick-and-place tasks â€” with visual explanation using Grad-CAM.

---
 Key Features

-  Simulated realistic robotic arm environment using PyBullet
-  Trained using Proximal Policy Optimization (PPO) from Stable Baselines3
-  Pick-and-place task with randomized object locations for better generalization
-  Learned grasping through reward shaping
-  Visualized decision-making using Grad-CAM heatmaps over input images

---
ğŸ“ Project Structure

```bash
robot_arm/
â”œâ”€â”€ env/
â”‚   â””â”€â”€ robot_env.py           
â”œâ”€â”€ train.py                   
â”œâ”€â”€ evaluate.py               
â”œâ”€â”€ evaluate_with_gradcam.py   
â”œâ”€â”€ robot_arm_model.zip        
â”œâ”€â”€ gradcam_step_*.png       
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

 Getting Started :

1ï¸âƒ£ Clone this repo:
git clone https://github.com/umme-aiman20/robot-arm-pick-and-place.git
cd robot-arm-pick-and-place

2ï¸âƒ£ Install dependencies:
pip install -r requirements.txt

3ï¸âƒ£ Run simulation with Grad-CAM:
python evaluate_with_gradcam.py


How Grad-CAM Works Here
Grad-CAM highlights image regions that the RL policy focuses on when choosing actions.
Youâ€™ll see colorful heatmaps overlayed on camera views, showing the modelâ€™s visual attention.

License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


Author:
@umme-aiman20




